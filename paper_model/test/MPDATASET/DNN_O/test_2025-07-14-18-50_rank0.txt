2025-07-14 18:50:53,885:[P:3763953]:Rank[0/1] => collecting env info (might take some time)
2025-07-14 18:50:58,909:[P:3763953]:Rank[0/1] 
PyTorch version: 2.5.1
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 22.04.5 LTS (x86_64)
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.35

Python version: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-6.8.0-59-generic-x86_64-with-glibc2.35
Is CUDA available: True
CUDA runtime version: 11.5.119
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: Tesla V100-SXM2-16GB
GPU 1: Tesla V100-SXM2-16GB
GPU 2: Tesla V100-SXM2-16GB
GPU 3: Tesla V100-SXM2-16GB

Nvidia driver version: 535.230.02
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                         x86_64
CPU op-mode(s):                       32-bit, 64-bit
Address sizes:                        43 bits physical, 48 bits virtual
Byte Order:                           Little Endian
CPU(s):                               32
On-line CPU(s) list:                  0-31
Vendor ID:                            AuthenticAMD
Model name:                           AMD EPYC 7F52 16-Core Processor
CPU family:                           23
Model:                                49
Thread(s) per core:                   2
Core(s) per socket:                   16
Socket(s):                            1
Stepping:                             0
Frequency boost:                      enabled
CPU max MHz:                          3500.0000
CPU min MHz:                          2500.0000
BogoMIPS:                             7000.26
Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sev sev_es
Virtualization:                       AMD-V
L1d cache:                            512 KiB (16 instances)
L1i cache:                            512 KiB (16 instances)
L2 cache:                             8 MiB (16 instances)
L3 cache:                             256 MiB (16 instances)
NUMA node(s):                         1
NUMA node0 CPU(s):                    0-31
Vulnerability Gather data sampling:   Not affected
Vulnerability Itlb multihit:          Not affected
Vulnerability L1tf:                   Not affected
Vulnerability Mds:                    Not affected
Vulnerability Meltdown:               Not affected
Vulnerability Mmio stale data:        Not affected
Vulnerability Reg file data sampling: Not affected
Vulnerability Retbleed:               Mitigation; untrained return thunk; SMT enabled with STIBP protection
Vulnerability Spec rstack overflow:   Mitigation; Safe RET
Vulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:             Mitigation; Retpolines; IBPB conditional; STIBP always-on; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected
Vulnerability Srbds:                  Not affected
Vulnerability Tsx async abort:        Not affected

Versions of relevant libraries:
[pip3] numpy==1.26.4
[pip3] torch==2.5.1
[pip3] torch-geometric==2.6.1
[pip3] torchaudio==2.5.1
[pip3] torchvision==0.20.1
[pip3] triton==3.1.0
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] libjpeg-turbo             2.0.0                h9bf148f_0    pytorch
[conda] mkl                       2023.1.0         h213fc3f_46344  
[conda] mkl-service               2.4.0           py310h5eee18b_2  
[conda] mkl_fft                   1.3.11          py310h5eee18b_0  
[conda] mkl_random                1.2.8           py310h1128e8f_0  
[conda] numpy                     1.26.4          py310h5f9d8c6_0  
[conda] numpy-base                1.26.4          py310hb5e798b_0  
[conda] pytorch                   2.5.1           py3.10_cuda12.1_cudnn9.1.0_0    pytorch
[conda] pytorch-cuda              12.1                 ha16c6d3_6    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torch-geometric           2.6.1                    pypi_0    pypi
[conda] torchaudio                2.5.1               py310_cu121    pytorch
[conda] torchtriton               3.1.0                     py310    pytorch
[conda] torchvision               0.20.1              py310_cu121    pytorch
2025-07-14 18:50:58,909:[P:3763953]:Rank[0/1] Namespace(cfg='../yaml/DNN_O.yaml', local_rank=0, port=9000, opts=[], num_gpus=1, distributed=False)
2025-07-14 18:50:58,909:[P:3763953]:Rank[0/1] AMP:
  ENABLED: False
  MEMORY_FORMAT: nchw
AUG:
  COLOR_JITTER: [0.4, 0.4, 0.4, 0.1, 0.0]
  DROPBLOCK_BLOCK_SIZE: 7
  DROPBLOCK_KEEP_PROB: 1.0
  DROPBLOCK_LAYERS: [3, 4]
  GAUSSIAN_BLUR: 0.0
  GRAY_SCALE: 0.0
  INTERPOLATION: 2
  MIXCUT: 0.0
  MIXCUT_AND_MIXUP: False
  MIXCUT_MINMAX: []
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 0.0
  MIXUP_SWITCH_PROB: 0.5
  RATIO: (0.75, 1.3333333333333333)
  SCALE: (0.08, 1.0)
  TIMM_AUG:
    USE_LOADER: False
    USE_TRANSFORM: False
BASE: ['']
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  DATASET: MPDATASET
  LABELMAP: 
  NUM_POINT: 500
  PROCESS_DATA: True
  ROOT: ../MPDATASET
  SAMPLER: default
  TARGET_SIZE: -1
  USE_NORMALS: True
  USE_UNIFORM_SAMPLE: False
DATA_DIR: 
DEBUG:
  DEBUG: False
DIST_BACKEND: nccl
FINETUNE:
  BASE_LR: 0.003
  BATCH_SIZE: 512
  EVAL_EVERY: 3000
  FINETUNE: False
  FROZEN_LAYERS: []
  LR_SCHEDULER:
    DECAY_TYPE: step
  TRAIN_MODE: True
  USE_TRAIN_AUG: False
GPUS: (0,)
INPUT:
  MEAN: [0.485, 0.456, 0.406]
  STD: [0.229, 0.224, 0.225]
LOSS:
  LABEL_SMOOTHING: 0.0
  LOSS: softmax
MODEL:
  INIT_WEIGHTS: False
  NAME: DNN_O
  NUM_CLASSES: 2
  NUM_CLASSES_MOL: 2
  NUM_CLASSES_ORDER_DISORDER: 2
  NUM_CLASSES_PHASE: 2
  SPEC:
    
MODEL_SUMMARY: False
MULTIPROCESSING_DISTRIBUTED: True
NAME: DNN_O
OUTPUT_DIR: ../test
PIN_MEMORY: True
PRINT_FREQ: 1
RANK: 0
TEST:
  BATCH_SIZE_PER_GPU: 8
  CENTER_CROP: True
  IMAGE_SIZE: [224, 224]
  INTERPOLATION: 2
  MODEL_FILE: 
  REAL_LABELS: False
  VALID_LABELS: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE_PER_GPU: 32
  BEGIN_EPOCH: 0
  CHECKPOINT: 
  CLIP_GRAD_NORM: 0.0
  DETECT_ANOMALY: False
  END_EPOCH: 100
  EVAL_BEGIN_EPOCH: 0
  GAMMA1: 0.99
  GAMMA2: 0.0
  IMAGE_SIZE: [224, 224]
  LR: 0.0001
  LR_SCHEDULER:
    
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZER: sgd
  OPTIMIZER_ARGS:
    
  SAVE_ALL_MODELS: False
  SCALE_LR: True
  SHUFFLE: True
  WD: 0.0001
  WITHOUT_WD_LIST: []
VERBOSE: True
WORKERS: 4
2025-07-14 18:50:58,910:[P:3763953]:Rank[0/1] => using 1 GPUs
2025-07-14 18:50:58,910:[P:3763953]:Rank[0/1] => saving config into: ../test/MPDATASET/DNN_O/config.yaml
2025-07-14 18:50:59,044:[P:3763953]:Rank[0/1] => load model file: ../test/MPDATASET/DNN_O/model_best.pth
2025-07-14 18:50:59,052:[P:3763953]:Rank[0/1] => get_model(
  (sa1): PointNetSetAbstraction_relu(
    (mlp_convs): ModuleList(
      (0): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (sa2_1): PointNetSetAbstraction_conv3_relu(
    (mlp_convs): ModuleList(
      (0): Conv2d(35, 64, kernel_size=(3, 1), stride=(3, 1))
      (1): Conv2d(64, 96, kernel_size=(3, 1), stride=(3, 1))
      (2): Conv2d(96, 128, kernel_size=(3, 1), stride=(3, 1))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (sa4): PointNetSetAbstraction_relu(
    (mlp_convs): ModuleList(
      (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1))
      (1-2): 2 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (mlp_bns): ModuleList(
      (0-2): 3 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fcl_res0): Linear(in_features=256, out_features=256, bias=True)
  (bnl_res0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fcl_res1): Linear(in_features=256, out_features=256, bias=True)
  (bnl_res1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fcl_res2): Linear(in_features=256, out_features=256, bias=True)
  (bnl_res2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc_lt1): Linear(in_features=256, out_features=256, bias=True)
  (bn_lt1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc_lt4): Linear(in_features=256, out_features=1, bias=True)
)
2025-07-14 18:50:59,052:[P:3763953]:Rank[0/1] Trainable Model Total Parameter: 	0.4M
2025-07-14 18:50:59,372:[P:3763953]:Rank[0/1] => start testing
2025-07-14 18:50:59,372:[P:3763953]:Rank[0/1] => switch to eval mode
2025-07-14 18:51:05,796:[P:3763953]:Rank[0/1] => synchronize...
2025-07-14 18:51:08,383:[P:3763953]:Rank[0/1] => TEST:	Loss_temp 0.0014	
2025-07-14 18:51:08,383:[P:3763953]:Rank[0/1] => switch to train mode
2025-07-14 18:51:08,383:[P:3763953]:Rank[0/1] => test duration time: 9.01s
2025-07-14 18:51:08,384:[P:3763953]:Rank[0/1] => finish testing
